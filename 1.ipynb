{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "9042af90f39abb4b2debd803231035b8255a1ba777e311bd64536878b3315c76"
   }
  },
  "interpreter": {
   "hash": "35c619e0b174f1cb694ad3db84010b6a3ee3a7a69128161967d9b21026d7f972"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import gzip\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_ratings=spark.read.csv(\"title.ratings.tsv.gz\",sep='\\t',header=True)\n",
    "name_basics=spark.read.csv(\"name.basics.tsv.gz\",sep='\\t',header=True)\n",
    "title_ratings.createOrReplaceTempView(\"title_ratings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_basics=name_basics.repartition(20)\n",
    "title_ratings=title_ratings.repartition(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_ratings=spark.sql(\"Select * from title_ratings where numVotes>50000\")\n",
    "title_ratings.createOrReplaceTempView(\"title_ratings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_basics=name_basics.selectExpr(\"nconst\",\"primaryName\",\"birthYear\",\"deathYear\",\"PrimaryProfession\",\\\n",
    "                                        'substring(knownForTitles, 1,9) as knownForTitle1',\n",
    "                                        'substring(knownForTitles, 11,9) as knownForTitle2',\\\n",
    "                                        'substring(knownForTitles, 21,9) as knownForTitle3',\\\n",
    "                                        'substring(knownForTitles, 31,9) as knownForTitle4')\n",
    "name_basics.createOrReplaceTempView(\"name_basics\")\n",
    "#name_basics=spark.sql(\"Select * from name_basics Limit 10000\")\n",
    "name_basics=spark.sql(\"Select * from name_basics where deathYear Like '%N%'\")\n",
    "name_basics.createOrReplaceTempView(\"name_basics\")\n",
    "name_basics=spark.sql(\"Select * from name_basics where birthYear>1970\")\n",
    "name_basics.createOrReplaceTempView(\"name_basics\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_table1=spark.sql(\"select nconst,primaryName,birthYear,deathYear,PrimaryProfession,rt.averageRating,rt.numVotes\\\n",
    "    from name_basics nm \\\n",
    "     inner join title_ratings rt on nm.knownForTitle1=rt.tconst\")\n",
    "reduced_table1.createOrReplaceTempView(\"reduced_table1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_table2=spark.sql(\"select nconst,primaryName,birthYear,deathYear,PrimaryProfession,rt.averageRating,rt.numVotes\\\n",
    "    from name_basics nm \\\n",
    "     inner join title_ratings rt on nm.knownForTitle2=rt.tconst where nm.knownForTitle2 is not Null\")\n",
    "reduced_table2.createOrReplaceTempView(\"reduced_table2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_table3=spark.sql(\"select nconst,primaryName,birthYear,deathYear,PrimaryProfession,rt.averageRating,rt.numVotes\\\n",
    "    from name_basics nm \\\n",
    "     inner join title_ratings rt on nm.knownForTitle3=rt.tconst where nm.knownForTitle3 is not Null\")\n",
    "reduced_table3.createOrReplaceTempView(\"reduced_table3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_table4=spark.sql(\"select nconst,primaryName,birthYear,deathYear,PrimaryProfession,rt.averageRating,rt.numVotes\\\n",
    "    from name_basics nm \\\n",
    "     inner join title_ratings rt on nm.knownForTitle4=rt.tconst where nm.knownForTitle4 is not Null\")\n",
    "reduced_table4.createOrReplaceTempView(\"reduced_table4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_table=reduced_table4.union(reduced_table3)\n",
    "reduced_table=reduced_table.union(reduced_table1)\n",
    "reduced_table=reduced_table.union(reduced_table2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_table.createOrReplaceTempView(\"reduced_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_table=spark.sql(\"select * from reduced_table where nconst in\\\n",
    "    (select nconst from reduced_table group by nconst having count(nconst)=4)\")\n",
    "reduced_table.createOrReplaceTempView(\"reduced_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_table=spark.sql(\"select primaryName,avg(averageRating),sum(numVotes) from reduced_table group by primaryName\\\n",
    "     order by sum(numVotes) desc limit 100\")\n",
    "reduced_table.createOrReplaceTempView(\"reduced_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_table.toPandas().to_csv('output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}